{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ftp_crawler.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1eSqYi6UImgiEDSMfBllqrdGHGzqWxT_p",
      "authorship_tag": "ABX9TyMNZNgpfS83I7DESan0G6ee",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/SloppyNoto/blob/master/ftp_crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV2Ur2lckLq5",
        "colab_type": "text"
      },
      "source": [
        "##FTP crawler\n",
        "\n",
        "This utility lists all files of 5+ MB recursively from a set directory on an FTP server. \n",
        "\n",
        "This utility is to accompany [Sloppy Noto](https://github.com/olaviinha/SloppyNoto) for finding suitable data file candidates for data to audio conversion.\n",
        "\n",
        "Note that it is not recommended to set `crawl_directory` to a top level directory, or in fact any upper level directory path (short path), if that directory contains a large subdirectory structure with a large number of files, such as _all data from an entire space mission_. It is recommended to use a low level directory path (long path). Should this recommendation be ignored, you are prohibited to blame this utility for _dying of old age_ before file list retrieval is completed (seriously, it may take a number of **hours**).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PHcOXUY5X6W",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Settings\n",
        "ftp_host = \"\" #@param {type:\"string\"}\n",
        "#@markdown <small>Upper level directories are not recommended as `crawl_directory`.</small>\n",
        "crawl_directory = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <small>Save file lists as a _.txt_ file in your Google Drive. At least use this if you chose to ignore the recommendation above.</small>\n",
        "save_txt = False #@param {type:\"boolean\"}\n",
        "#@markdown <small>Path to a directory in your Google Drive where the txt will be saved.</small>\n",
        "save_path = \"space_data\" #@param {type:\"string\"}\n",
        "\n",
        "basedir = crawl_directory\n",
        "\n",
        "force_setup = False\n",
        "if save_txt == True:\n",
        "  import os\n",
        "  # inhagcutils\n",
        "  if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "    %cd /content/\n",
        "    !pip -q install import-ipynb\n",
        "    !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "  import import_ipynb\n",
        "  from inhagcutils import *\n",
        "\n",
        "  # Mount Drive\n",
        "  if not os.path.isdir('/content/drive') and force_setup == False:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  # Drive symlink\n",
        "  if not os.path.isdir('/content/mydrive') and force_setup == False:\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root_set = True\n",
        "  drive_root = '/content/mydrive/'\n",
        "\n",
        "  dir_tmp = '/content/tmp/'\n",
        "  create_dirs([dir_tmp])\n",
        "  save_path = fix_path(drive_root+save_path)\n",
        "\n",
        "if not 'ftputil_installed' in globals():\n",
        "  !pip install ftputil\n",
        "  ftputil_installed = True\n",
        "\n",
        "\n",
        "all_files = []\n",
        "gigs = []\n",
        "half_gigs = []\n",
        "texas_pennies = []\n",
        "fiddies = []\n",
        "small = []\n",
        "extra_small = []\n",
        "exxxtra_small = []\n",
        "b = 1000000\n",
        "\n",
        "class c:\n",
        "  title = '\\033[96m'\n",
        "  ok = '\\033[92m'\n",
        "  okb = '\\033[94m'\n",
        "  warn = '\\033[93m'\n",
        "  fail = '\\033[31m'\n",
        "  endc = '\\033[0m'\n",
        "  bold = '\\033[1m'\n",
        "  u = '\\033[4m'\n",
        "\n",
        "def op(typex, msg, value=''):\n",
        "  if value != '':\n",
        "    print(typex+msg+c.endc, end=' ')\n",
        "    print(value)\n",
        "  else:\n",
        "    print(typex+msg+c.endc)\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import ftplib\n",
        "import ftputil\n",
        "import fnmatch\n",
        "if save_txt == True:\n",
        "  txt = save_path+'ftp_'+ftp_host+'filelist_'+rnd_str(4)+'.txt'\n",
        "  log_all = open(txt, 'a+')\n",
        "  log_all.write('FTP host: '+ftp_host+'\\n')\n",
        "  log_all.write('FTP dir: '+basedir+'\\n\\n')\n",
        "  # log_all.close()\n",
        "op(c.title, 'Logging in to '+ftp_host+'...')\n",
        "host = ftputil.FTPHost(ftp_host, 'anonymous', 'anonymous@domain.com') # ftp host info\n",
        "recursive = host.walk(basedir, topdown=True, onerror=None) # recursive search \n",
        "op(c.warn, 'Retrieval in progress...')\n",
        "for root, dirs, files in recursive:\n",
        "  for name in files:\n",
        "    fullpath = os.path.join(root, name)\n",
        "    size = host.path.getsize(fullpath)\n",
        "    all_files.append([size, fullpath])\n",
        "    if size > 1000*b:\n",
        "      gigs.append([size, fullpath])\n",
        "    if size < 1000*b and size > 500*b:\n",
        "      half_gigs.append([size, fullpath])\n",
        "    if size < 500*b and size > 100*b:\n",
        "      texas_pennies.append([size, fullpath])\n",
        "    if size < 100*b and size > 50*b:\n",
        "      fiddies.append([size, fullpath])\n",
        "    if size < 50*b and size > 20*b:\n",
        "      small.append([size, fullpath])\n",
        "    if size < 20*b and size > 10*b:\n",
        "      extra_small.append([size, fullpath])\n",
        "    if size < 10*b and size > 5*b:\n",
        "      exxxtra_small.append([size, fullpath])\n",
        "op(c.ok, 'Retrieval compelte.\\n\\n')\n",
        "\n",
        "b = 1000000\n",
        "\n",
        "op(c.title, 'Files by size range\\n')\n",
        "\n",
        "# log_all = ''\n",
        "# save_txt = False\n",
        "def apnd(content):\n",
        "  global log_all, txt\n",
        "  log_all = open(txt, 'a+')\n",
        "  log_all.write(content)\n",
        "  log_all.close()\n",
        "\n",
        "def print_filelist(list, title):\n",
        "  global log_all, save_txt\n",
        "  op(c.warn, '\\n'+title+':')\n",
        "  if save_txt == True:\n",
        "    log_all.write('\\n'+title+'\\n')\n",
        "  for s, f in list:\n",
        "    line = str('{:.2f}'.format(round(s/b, 2)))+' MB: ftp://'+ftp_host+f\n",
        "    print(line)\n",
        "    if save_txt == True:\n",
        "      log_all.write(line+'\\n')\n",
        "\n",
        "if len(gigs) > 0:\n",
        "  print_filelist(gigs, 'Over 1 GB')\n",
        "\n",
        "if len(half_gigs) > 0:\n",
        "  print_filelist(half_gigs, '0,5-1 GB')\n",
        "\n",
        "if len(texas_pennies) > 0:\n",
        "  print_filelist(texas_pennies, '100-500 MB')\n",
        "\n",
        "if len(fiddies) > 0:\n",
        "  print_filelist(fiddies, '50-100 MB')\n",
        "\n",
        "if len(small) > 0:\n",
        "  print_filelist(small, '20-50 MB')\n",
        "\n",
        "if len(extra_small) > 0:\n",
        "  print_filelist(extra_small, '10-20 MB')\n",
        "\n",
        "if len(exxxtra_small) > 0:\n",
        "  print_filelist(exxxtra_small, '5-10 MB')\n",
        "\n",
        "if save_txt == True:\n",
        "  log_all.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}